<!DOCTYPE html><html lang="en-gb"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Get all site urls with python - iTheo.Tech</title><meta name="description" content="So more screamingfrog scraping in Python. Let's get all URLs from a site and when the URL contains Non-ascii characters or underscores or uppercase characters put them in a separate CSV file. I guess I'm up to the challenge, so the assignment is: Write a&hellip;"><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://itheo.tech/get-all-site-urls-with-python.html"><link rel="alternate" type="application/atom+xml" href="https://itheo.tech/feed.xml"><link rel="alternate" type="application/json" href="https://itheo.tech/feed.json"><meta property="og:title" content="Get all site urls with python"><meta property="og:image" content="https://itheo.tech/media/posts/70/614bf2d682f2c37a9e319b80f7926f25.jpeg"><meta property="og:image:width" content="1600"><meta property="og:image:height" content="1067"><meta property="og:site_name" content="iTheo.Tech"><meta property="og:description" content="So more screamingfrog scraping in Python. Let's get all URLs from a site and when the URL contains Non-ascii characters or underscores or uppercase characters put them in a separate CSV file. I guess I'm up to the challenge, so the assignment is: Write a&hellip;"><meta property="og:url" content="https://itheo.tech/get-all-site-urls-with-python.html"><meta property="og:type" content="article"><link rel="stylesheet" href="https://itheo.tech/assets/css/style.css?v=6fbb1e8931a5afe843374fd67c192c86"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://itheo.tech/get-all-site-urls-with-python.html"},"headline":"Get all site urls with python","datePublished":"2023-04-04T05:15","dateModified":"2024-06-01T19:42","image":{"@type":"ImageObject","url":"https://itheo.tech/media/posts/70/614bf2d682f2c37a9e319b80f7926f25.jpeg","height":1067,"width":1600},"description":"So more screamingfrog scraping in Python. Let's get all URLs from a site and when the URL contains Non-ascii characters or underscores or uppercase characters put them in a separate CSV file. I guess I'm up to the challenge, so the assignment is: Write a&hellip;","author":{"@type":"Person","name":"Theo van der Sluijs","url":"https://itheo.tech/authors/theo-van-der-sluijs/"},"publisher":{"@type":"Organization","name":"Theo van der Sluijs","logo":{"@type":"ImageObject","url":"https://itheo.tech/media/website/itheo.tech-500x125-logo.png","height":125,"width":500}}}</script><noscript><style>img[loading] {
                    opacity: 1;
                }</style></noscript></head><body><div class="site-container"><header class="top" id="js-header"><a class="logo" href="https://itheo.tech/"><img src="https://itheo.tech/media/website/itheo.tech-500x125-logo.png" alt="iTheo.Tech" width="500" height="125"></a><div class="search"><div class="search__overlay js-search-overlay"><div class="search__overlay-inner"><button class="search__close js-search-close" aria-label="Close">Close</button></div></div><button class="search__btn js-search-btn" aria-label="Search"><svg role="presentation" focusable="false"><use xlink:href="https://itheo.tech/assets/svg/svg-map.svg#search"/></svg></button></div></header><main><article class="post"><div class="hero"><figure class="hero__image hero__image--overlay"><img src="https://itheo.tech/media/posts/70/614bf2d682f2c37a9e319b80f7926f25.jpeg" srcset="https://itheo.tech/media/posts/70/responsive/614bf2d682f2c37a9e319b80f7926f25-xs.webp 300w, https://itheo.tech/media/posts/70/responsive/614bf2d682f2c37a9e319b80f7926f25-sm.webp 480w, https://itheo.tech/media/posts/70/responsive/614bf2d682f2c37a9e319b80f7926f25-md.webp 768w, https://itheo.tech/media/posts/70/responsive/614bf2d682f2c37a9e319b80f7926f25-lg.webp 1024w, https://itheo.tech/media/posts/70/responsive/614bf2d682f2c37a9e319b80f7926f25-xl.webp 1360w, https://itheo.tech/media/posts/70/responsive/614bf2d682f2c37a9e319b80f7926f25-2xl.webp 1600w" sizes="(max-width: 1600px) 100vw, 1600px" loading="eager" height="1067" width="1600" alt=""></figure><header class="hero__content"><div class="wrapper"><div class="post__meta"><time datetime="2023-04-04T05:15">April 4, 2023</time></div><h1>Get all site urls with python</h1><div class="post__meta post__meta--author"><img src="https://itheo.tech/media/website/64.png" loading="eager" height="512" width="512" class="post__author-thumb" alt="Theo van der Sluijs"> <a href="https://itheo.tech/authors/theo-van-der-sluijs/" class="feed__author">Theo van der Sluijs</a></div></div></header></div><div class="wrapper post__entry"><p>So more screamingfrog scraping in Python. Let's get all URLs from a site and when the URL contains Non-ascii characters or underscores or uppercase characters put them in a separate CSV file.</p><p>I guess I'm up to the challenge, so the assignment is:</p><blockquote><p>Write a python script that recursively checks a site and get all Urls, put all the URLs in a CSV file named "all_urls.csv" and put the urls that have Non asscii characters or underscores or uppercase characters in a csv file named "wrong_urls.csv. There is no need to scan urls that fall outside the domain. Ask for a site domain with input when the scripts starts.</p></blockquote><p>And off we go!</p><p>To achieve this, you can use the 'requests' and 'BeautifulSoup' libraries to fetch and parse the HTML content of the domain. You can then collect all the URLs within the domain and write them to the respective CSV files based on their characteristics.</p><p>Before you proceed, make sure you have installed the required libraries by running:</p><pre><code class="lang-python">pip install requests beautifulsoup4<restore-line-break></restore-line-break></code></pre><p>Here's the Python script for your requirement:</p><pre><code class="lang-python"><span class="hljs-keyword">import</span> requests<restore-line-break><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup<restore-line-break><span class="hljs-keyword">import</span> csv<restore-line-break><span class="hljs-keyword">from</span> urllib.parse <span class="hljs-keyword">import</span> urljoin<restore-line-break><span class="hljs-keyword">import</span> re<restore-line-break><restore-line-break><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_all_links_recursive</span>(<span class="hljs-params">url, domain, visited=None</span>):</span><restore-line-break>    <span class="hljs-keyword">if</span> visited <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<restore-line-break>        visited = set()<restore-line-break><restore-line-break>    <span class="hljs-keyword">if</span> url <span class="hljs-keyword">in</span> visited:<restore-line-break>        <span class="hljs-keyword">return</span> visited<restore-line-break><restore-line-break>    visited.add(url)<restore-line-break><restore-line-break>    page = requests.get(url)<restore-line-break>    soup = BeautifulSoup(page.content, <span class="hljs-string">"html.parser"</span>)<restore-line-break><restore-line-break>    <span class="hljs-keyword">for</span> link <span class="hljs-keyword">in</span> soup.find_all(<span class="hljs-string">"a"</span>):<restore-line-break>        href = link.get(<span class="hljs-string">"href"</span>)<restore-line-break>        <span class="hljs-keyword">if</span> href:<restore-line-break>            abs_url = urljoin(domain, href)<restore-line-break>            <span class="hljs-keyword">if</span> abs_url.startswith(domain) <span class="hljs-keyword">and</span> abs_url <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> visited:<restore-line-break>                visited = get_all_links_recursive(abs_url, domain, visited)<restore-line-break><restore-line-break>    <span class="hljs-keyword">return</span> visited<restore-line-break><restore-line-break><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">is_wrong_url</span>(<span class="hljs-params">url</span>):</span><restore-line-break>    <span class="hljs-keyword">if</span> re.search(<span class="hljs-string">r"[^x00-x7F]|_|[A-Z]"</span>, url):<restore-line-break>        <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><restore-line-break>    <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><restore-line-break><restore-line-break><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">main</span>():</span><restore-line-break>    domain = input(<span class="hljs-string">"Enter the domain URL: "</span>)<restore-line-break><restore-line-break>    all_links = get_all_links_recursive(domain, domain)<restore-line-break><restore-line-break>    all_urls = []<restore-line-break>    wrong_urls = []<restore-line-break><restore-line-break>    <span class="hljs-keyword">for</span> link <span class="hljs-keyword">in</span> all_links:<restore-line-break>        <span class="hljs-keyword">if</span> is_wrong_url(link):<restore-line-break>            wrong_urls.append(link)<restore-line-break>        <span class="hljs-keyword">else</span>:<restore-line-break>            all_urls.append(link)<restore-line-break><restore-line-break>    <span class="hljs-keyword">with</span> open(<span class="hljs-string">"all_urls.csv"</span>, <span class="hljs-string">"w"</span>, newline=<span class="hljs-string">""</span>) <span class="hljs-keyword">as</span> csvfile:<restore-line-break>        writer = csv.writer(csvfile)<restore-line-break>        writer.writerow([<span class="hljs-string">"URL"</span>])<restore-line-break>        <span class="hljs-keyword">for</span> url <span class="hljs-keyword">in</span> all_urls:<restore-line-break>            writer.writerow([url])<restore-line-break><restore-line-break>    <span class="hljs-keyword">with</span> open(<span class="hljs-string">"wrong_urls.csv"</span>, <span class="hljs-string">"w"</span>, newline=<span class="hljs-string">""</span>) <span class="hljs-keyword">as</span> csvfile:<restore-line-break>        writer = csv.writer(csvfile)<restore-line-break>        writer.writerow([<span class="hljs-string">"Wrong URL"</span>])<restore-line-break>        <span class="hljs-keyword">for</span> url <span class="hljs-keyword">in</span> wrong_urls:<restore-line-break>            writer.writerow([url])<restore-line-break><restore-line-break>    print(<span class="hljs-string">"CSV files created: all_urls.csv, wrong_urls.csv"</span>)<restore-line-break><restore-line-break><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:<restore-line-break>    main()<restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></code></pre><p>This script does the following:</p><ol><li><p>Prompts the user for the domain URL.</p></li><li><p>Recursively fetches all the links within the domain using the <code>get_all_links_recursive</code> function.</p></li><li><p>Classifies the URLs as wrong if they contain non-ASCII characters, underscores, or uppercase characters.</p></li><li><p>Writes the URLs to 'all_urls.csv' and 'wrong_urls.csv' files based on their classification.</p></li></ol><p>Please note that this script still assumes all URLs within the domain are either absolute URLs or relative URLs that can be resolved using the domain URL. Additionally, it does not handle JavaScript rendered content, which may cause some URLs rendered by JavaScript to be missed.</p></div><footer class="wrapper post__footer"><p class="post__last-updated">This article was updated on June 1, 2024</p><div class="post__share"></div><div class="post__bio bio"><img src="https://itheo.tech/media/website/64.png" loading="lazy" height="512" width="512" class="bio__avatar" alt="Theo van der Sluijs"><div><h3 class="bio__name"><a href="https://itheo.tech/authors/theo-van-der-sluijs/" rel="author">Theo van der Sluijs</a></h3></div></div></footer></article><nav class="post__nav"><div class="post__nav-inner"><div class="post__nav-prev"><svg width="1.041em" height="0.416em" aria-hidden="true"><use xlink:href="https://itheo.tech/assets/svg/svg-map.svg#arrow-prev"/></svg> <a href="https://itheo.tech/find-images-on-your-site-without-an-alt-tag.html" class="post__nav-link" rel="prev"><span>Previous</span> Find images on your site without an ALT tag</a></div><div class="post__nav-next"><a href="https://itheo.tech/get-all-site-urls-without-images-javascript-and-css-files.html" class="post__nav-link" rel="next"><span>Next</span> Get all site urls, without images, javascript and css files </a><svg width="1.041em" height="0.416em" aria-hidden="true"><use xlink:href="https://itheo.tech/assets/svg/svg-map.svg#arrow-next"/></svg></div></div></nav><div class="post__related related"><div class="wrapper"><h2 class="h5 related__title">You should also read:</h2><article class="related__item"><div class="feed__meta"><time datetime="2018-10-03T22:00" class="feed__date">October 3, 2018</time></div><h3 class="h1"><a href="https://itheo.tech/scraping-contact-data-with-python-export-to-csv.html">Scraping contact data with Python export to csv</a></h3></article><article class="related__item"><div class="feed__meta"><time datetime="2018-11-30T23:00" class="feed__date">November 30, 2018</time></div><h3 class="h1"><a href="https://itheo.tech/image-resize-python-automation-script.html">Image resize python automation script</a></h3></article><article class="related__item"><div class="feed__meta"><time datetime="2018-12-19T23:00" class="feed__date">December 19, 2018</time></div><h3 class="h1"><a href="https://itheo.tech/get-colors-from-images-python-script.html">Get colors from images python script</a></h3></article></div></div></main><footer class="footer"><div class="footer__copyright"><p>iTheo.Tech</p></div><button onclick="backToTopFunction()" id="backToTop" class="footer__bttop" aria-label="Back to top" title="Back to top"><svg><use xlink:href="https://itheo.tech/assets/svg/svg-map.svg#toparrow"/></svg></button></footer></div><script defer="defer" src="https://itheo.tech/assets/js/scripts.min.js?v=f47c11534595205f20935f0db2a62a85"></script><script>window.publiiThemeMenuConfig={mobileMenuMode:'sidebar',animationSpeed:300,submenuWidth: 'auto',doubleClickTime:500,mobileMenuExpandableSubmenus:true,relatedContainerForOverlayMenuSelector:'.top'};</script><script>var images = document.querySelectorAll('img[loading]');
        for (var i = 0; i < images.length; i++) {
            if (images[i].complete) {
                images[i].classList.add('is-loaded');
            } else {
                images[i].addEventListener('load', function () {
                    this.classList.add('is-loaded');
                }, false);
            }
        }</script></body></html>