<!DOCTYPE html><html lang="en-gb"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Scraping contact data with Python export to csv - iTheo.Tech</title><meta name="description" content="Scraping data with Python is very easy to do and to learn with this Example. With a few lines of Python code you will be able to scrape almost any site. So I saw this assignment on upwork.com or freelancer.com and I just wanted to&hellip;"><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://itheo.tech/scraping-contact-data-with-python-export-to-csv.html"><link rel="alternate" type="application/atom+xml" href="https://itheo.tech/feed.xml"><link rel="alternate" type="application/json" href="https://itheo.tech/feed.json"><meta property="og:title" content="Scraping contact data with Python export to csv"><meta property="og:image" content="https://itheo.tech/media/posts/7/2GIBo-yv4.jpeg"><meta property="og:image:width" content="1600"><meta property="og:image:height" content="1067"><meta property="og:site_name" content="iTheo.Tech"><meta property="og:description" content="Scraping data with Python is very easy to do and to learn with this Example. With a few lines of Python code you will be able to scrape almost any site. So I saw this assignment on upwork.com or freelancer.com and I just wanted to&hellip;"><meta property="og:url" content="https://itheo.tech/scraping-contact-data-with-python-export-to-csv.html"><meta property="og:type" content="article"><link rel="stylesheet" href="https://itheo.tech/assets/css/style.css?v=6fbb1e8931a5afe843374fd67c192c86"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://itheo.tech/scraping-contact-data-with-python-export-to-csv.html"},"headline":"Scraping contact data with Python export to csv","datePublished":"2018-10-03T22:00","dateModified":"2024-06-01T19:42","image":{"@type":"ImageObject","url":"https://itheo.tech/media/posts/7/2GIBo-yv4.jpeg","height":1067,"width":1600},"description":"Scraping data with Python is very easy to do and to learn with this Example. With a few lines of Python code you will be able to scrape almost any site. So I saw this assignment on upwork.com or freelancer.com and I just wanted to&hellip;","author":{"@type":"Person","name":"Theo van der Sluijs","url":"https://itheo.tech/authors/theo-van-der-sluijs/"},"publisher":{"@type":"Organization","name":"Theo van der Sluijs","logo":{"@type":"ImageObject","url":"https://itheo.tech/media/website/itheo.tech-500x125-logo.png","height":125,"width":500}}}</script><noscript><style>img[loading] {
                    opacity: 1;
                }</style></noscript></head><body><div class="site-container"><header class="top" id="js-header"><a class="logo" href="https://itheo.tech/"><img src="https://itheo.tech/media/website/itheo.tech-500x125-logo.png" alt="iTheo.Tech" width="500" height="125"></a><div class="search"><div class="search__overlay js-search-overlay"><div class="search__overlay-inner"><button class="search__close js-search-close" aria-label="Close">Close</button></div></div><button class="search__btn js-search-btn" aria-label="Search"><svg role="presentation" focusable="false"><use xlink:href="https://itheo.tech/assets/svg/svg-map.svg#search"/></svg></button></div></header><main><article class="post"><div class="hero"><figure class="hero__image hero__image--overlay"><img src="https://itheo.tech/media/posts/7/2GIBo-yv4.jpeg" srcset="https://itheo.tech/media/posts/7/responsive/2GIBo-yv4-xs.webp 300w, https://itheo.tech/media/posts/7/responsive/2GIBo-yv4-sm.webp 480w, https://itheo.tech/media/posts/7/responsive/2GIBo-yv4-md.webp 768w, https://itheo.tech/media/posts/7/responsive/2GIBo-yv4-lg.webp 1024w, https://itheo.tech/media/posts/7/responsive/2GIBo-yv4-xl.webp 1360w, https://itheo.tech/media/posts/7/responsive/2GIBo-yv4-2xl.webp 1600w" sizes="(max-width: 1600px) 100vw, 1600px" loading="eager" height="1067" width="1600" alt=""></figure><header class="hero__content"><div class="wrapper"><div class="post__meta"><time datetime="2018-10-03T22:00">October 3, 2018</time></div><h1>Scraping contact data with Python export to csv</h1><div class="post__meta post__meta--author"><img src="https://itheo.tech/media/website/64.png" loading="eager" height="512" width="512" class="post__author-thumb" alt="Theo van der Sluijs"> <a href="https://itheo.tech/authors/theo-van-der-sluijs/" class="feed__author">Theo van der Sluijs</a></div></div></header></div><div class="wrapper post__entry"><p>Scraping data with Python is very easy to do and to learn with this Example. With a few lines of Python code you will be able to scrape almost any site.</p><p>So I saw this assignment on upwork.com or <a target="_blank" href="https://www.freelancer.com/get/vw247161vw" rel="noopener">freelancer.com</a> and I just wanted to see if I could do it with python.</p><p>The assignment was to scrape the contact information from http://www.petfoodnz.co.nz with a PHP script. Now I’ve done a lot of development in PHP but since I’ve met Python I just don’t really like PHP anymore. If you just want the whole script and don’t want to read my explanation just scroll way down.</p><h2 id="heading-needed-for-web-scraping">Needed for web scraping</h2><p>So there are a few things to know before you start. I only write and tested it in Python 3.x so I’m not sure if this script will work in python 2.7. I can also not give you directions on how to get it working in python 2.7.</p><p>I do understand that a lot of people like python 2.7 over 3.x but… as 2.7 will cease to exists it might be a good start to learn and use 3.x.</p><p>You also need some extra library’s for this script to work.</p><p>If you use python a lot you will recognize a few of the modules I’ve used.</p><pre><code class="lang-bash">pip install requests<restore-line-break>pip install lxml<restore-line-break>pip install beautifulsoup4<restore-line-break></restore-line-break></restore-line-break></restore-line-break></code></pre><p>I’m not really sure why python 3 did not add requests to it’s standard library. But you will need it to call a URL and get all of it’s content back.</p><p><strong>Beautiful Soup</strong> is a library that makes it easy to scrape information from web pages. It sits atop an HTML or XML parser, providing Pythonic idioms for iterating, searching, and modifying the parse tree.</p><p><strong>lxml</strong> is the most feature-rich and easy-to-use library for processing XML and HTML in the Python language.</p><p>As Beautiful Soup and lxml seem to be the same there is a mayor difference between the two. It is not possible to get parts of a HTML page thru the use of xpath. As I really like beautiful soup, for this small assignment where the site that I’m scraping does not use class and id-names you can only use lxml to get the data fairly easily.</p><h2 id="heading-the-scraping-code">The scraping code</h2><p>So let’s start with the code and let’s start at the bottom.</p><p>I really like using classes as in my opinion they are more powerful, easier to use and you can when a one file project becomes a somewhat bigger project use it as an OO part.</p><p>Now when using a classed file you might want to use <code>if __name__ == '__main__':</code> statement at the end of the file.</p><p>In this way you can use the class when putting the file itself to work and when you use this class in other projects and import it it will only be called from that other file. So pretty handy!</p><pre><code class="lang-python"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:<restore-line-break>    g = getAddress(<span class="hljs-string">"http://www.petfoodnz.co.nz/directory.htm"</span>, <span class="hljs-string">"contacts.csv"</span>)<restore-line-break></restore-line-break></restore-line-break></code></pre><p>So… in this example the <code>g =</code> part is not really necessary but it just puts the class in it. The real magic happens the the <code>getAddress</code> part.</p><p>It calls a url to start scraping and it will put all the found information in the contacts.csv file</p><h2 id="heading-set-start-vars-and-start-scraping">Set start vars and start scraping</h2><p>When starting up this class I’m setting some variables to get going.</p><p>I’m setting the filename to be used when creating the csv file. I’m getting the main url for later usage so it easier to call all the separate company pages, where the actual data is.</p><p>Then I call the start function to get all the company page date to scrape with <code>self.geturlcontent</code>.</p><p>When that function returns actual data (and not <code>None</code>) the script can start scraping the separate company urls with <code>self.geturlsfrommain</code>.</p><p>Than it will process these urls with <code>self.processurls</code></p><p>And the creating of the csv (excel file) can start with <code>self.createexcel()</code></p><pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, url=None, filename=<span class="hljs-string">"contacts.cvs"</span></span>):</span><restore-line-break>    <span class="hljs-keyword">if</span> url <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<restore-line-break>        self.filename = filename<restore-line-break>        self.url = url<restore-line-break>        self.mainurl = <span class="hljs-string">"{0.scheme}://{0.netloc}/"</span>.format(urlsplit(self.url))<restore-line-break>        self.addresses = []<restore-line-break>        content = self.geturlcontent(self.url)<restore-line-break>        <span class="hljs-keyword">if</span> content:<restore-line-break>            self.urls = self.geturlsfrommain(content)<restore-line-break><restore-line-break>        self.processurls(self.urls)<restore-line-break>        self.createexcel()<restore-line-break><restore-line-break>    <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></code></pre><h2 id="heading-get-the-url-content">Get the url content</h2><p>Getting the the content of a page is not really difficult. You can use requests for this. It also checks if you get a 200 status codes back, which means that you actually get a server response.</p><p>So the below code is for getting the main page where all the links to all the other company pages are and it is uses for getting the html data from all the company pages.</p><p>It’s pretty straight forward. When it did not get any data it will return a <code>False</code></p><pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">geturlcontent</span>(<span class="hljs-params">self, url</span>):</span><restore-line-break>    result = <span class="hljs-literal">None</span><restore-line-break>    <span class="hljs-keyword">if</span> url <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<restore-line-break>        result = requests.get(url)<restore-line-break><restore-line-break>    <span class="hljs-keyword">if</span> result.status_code == <span class="hljs-number">200</span>:<restore-line-break>        <span class="hljs-keyword">return</span> result.content<restore-line-break><restore-line-break>    <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></code></pre><h2 id="heading-getting-all-company-urls">Getting all company urls</h2><p>So on the first page we need scraping all the company links are present.</p><p>So with Beautifulsoup we can process the content scrapped with requests and start searching for all a (href’s) where the href (url) starts with companies.</p><p>When scrapped this part returns a list with all the urls found on the page that start with companies</p><p>When none where found it will return <code>None</code></p><pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">geturlsfrommain</span>(<span class="hljs-params">self, content</span>):</span><restore-line-break>    soup = BeautifulSoup(content, features=<span class="hljs-string">"lxml"</span>)<restore-line-break>    links = []<restore-line-break>    <span class="hljs-keyword">for</span> link <span class="hljs-keyword">in</span> soup.findAll(<span class="hljs-string">'a'</span>, attrs={<span class="hljs-string">'href'</span>: re.compile(<span class="hljs-string">"^companies"</span>)}):<restore-line-break>        links.append(link.get(<span class="hljs-string">'href'</span>))<restore-line-break><restore-line-break>    <span class="hljs-keyword">return</span> links<restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></code></pre><h2 id="heading-processing-the-urls">Processing the Urls</h2><p>So this is where the url processing starts. It is build in two separate functions the first loops thru the URL’s, the second gets the data from the urls.</p><p>So while looping thru the urls it reuses the <code>geturlcontent</code> that we also used in getting the html from the main page.</p><p>After getting that HTML data we put it in the second function that get’s the company address info from that data.</p><pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">processurls</span>(<span class="hljs-params">self, urls</span>):</span><restore-line-break>    <span class="hljs-keyword">for</span> u <span class="hljs-keyword">in</span> urls:<restore-line-break>        url = <span class="hljs-string">"{}{}"</span>.format(self.mainurl,u)<restore-line-break>        print(url)<restore-line-break>        content = self.geturlcontent(url)<restore-line-break>        <span class="hljs-keyword">if</span> content:<restore-line-break>            data = self.getdatafromurls(content)<restore-line-break>            self.addresses.append(data)<restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></code></pre><p>So this second function uses the xpath to get the data from the HTML. Now, whenever this site will change (putting new tables in it) this will break. But as this site is not using any class or id names there is no real other way to do this.</p><p>It gets the HTML part in the 2 table with the first TD and the 9th TD which is a table again.</p><p>In the function I use that table to loop thru the TR’s and get the data from the TD’s (are you still here ? )</p><p>So no, not really to easy…. not difficult either but… it would have been easier with class or id names.</p><p>So, after 10 loops I just stop, hoping nothing really important comes after that 10 TR’s.</p><p>I clean up the data (next chapter) before using it in the CSV.</p><pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getdatafromurls</span>(<span class="hljs-params">self, content</span>):</span><restore-line-break>    root = html.fromstring(content)<restore-line-break>    data = {}<restore-line-break><restore-line-break>    xpathdata= <span class="hljs-string">"/html/body/div/table[2]/tr[1]/td[9]/table"</span><restore-line-break>    table = root.xpath(xpathdata)<restore-line-break>    i = <span class="hljs-number">0</span><restore-line-break>    <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> table[<span class="hljs-number">0</span>].xpath(<span class="hljs-string">".//tr"</span>):<restore-line-break>        values = row.xpath(<span class="hljs-string">".//td"</span>)<restore-line-break><restore-line-break>        <span class="hljs-keyword">if</span> values[<span class="hljs-number">2</span>].text_content() != <span class="hljs-string">''</span>:<restore-line-break>            key = values[<span class="hljs-number">0</span>].text_content()<restore-line-break>            key = self.removerubish(key)<restore-line-break><restore-line-break>            value = values[<span class="hljs-number">2</span>].text_content()<restore-line-break>            value = self.removerubishvalue(value)<restore-line-break><restore-line-break>        rawdata = {key: value}<restore-line-break>        data.update(rawdata)<restore-line-break><restore-line-break>        i += <span class="hljs-number">1</span><restore-line-break>        <span class="hljs-keyword">if</span> i == <span class="hljs-number">10</span>:<restore-line-break>            <span class="hljs-keyword">break</span><restore-line-break><restore-line-break>    <span class="hljs-keyword">return</span> data<restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></code></pre><h2 id="heading-cleaning-shit-up">Cleaning shit up</h2><p>I’ve written 3 small functions to get rid of tabs, line returns, some jibberish and gobbledygook before using it and putting it in the csv file.</p><pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">removerubish</span>(<span class="hljs-params">self,key</span>):</span><restore-line-break>    key = re.sub(<span class="hljs-string">'\:|[ \t]+'</span>, <span class="hljs-string">''</span>, key)<restore-line-break>    key = key.lower()<restore-line-break>    <span class="hljs-keyword">return</span> key<restore-line-break><restore-line-break><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">removerubishvalue</span>(<span class="hljs-params">self,value</span>):</span><restore-line-break>    value = re.sub(<span class="hljs-string">'[ \t]+'</span>, <span class="hljs-string">' '</span>, value)<restore-line-break>    value = re.sub(<span class="hljs-string">'\n'</span>, <span class="hljs-string">''</span>, value)<restore-line-break>    value = re.sub(<span class="hljs-string">'\r'</span>, <span class="hljs-string">''</span>, value)<restore-line-break>    value = re.sub(<span class="hljs-string">r'[^\x00-\x7F]+'</span>,<span class="hljs-string">''</span>,value)<restore-line-break>    <span class="hljs-keyword">return</span> value<restore-line-break><restore-line-break><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">text</span>(<span class="hljs-params">self,elt</span>):</span><restore-line-break>    <span class="hljs-keyword">return</span> elt.text_content().replace(<span class="hljs-string">u'\xa0'</span>, <span class="hljs-string">u' '</span>)<restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></code></pre><h2 id="heading-creating-the-csv">Creating the csv</h2><p>Creating the csv is really simple. You first get the keys inside the dictionary, then open the file you want to write all the data into, where you give in the keys with writeheader you want to use as first line (header). And with one statement you write all the data into the file.</p><p>I’m using <code>extrasaction='ignore'</code> as I had a few addresses that had the problem they where having more address information than others. And when the keys don’t match up you will get a big error.</p><pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">createexcel</span>(<span class="hljs-params">self</span>):</span><restore-line-break>    keys = self.addresses[<span class="hljs-number">0</span>].keys()<restore-line-break>    <span class="hljs-keyword">with</span> open(self.filename, <span class="hljs-string">'w'</span>) <span class="hljs-keyword">as</span> output_file:<restore-line-break>    dict_writer = csv.DictWriter(output_file, keys, extrasaction=<span class="hljs-string">'ignore'</span>)<restore-line-break>    dict_writer.writeheader()<restore-line-break>    dict_writer.writerows(self.addresses)<restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></code></pre><p>Is this the best script I’ve ever written? Nope! Can it be better? Yup! But it does the job.</p><pre><code class="lang-python"><span class="hljs-comment">### The whole Python contact data scraping script</span><restore-line-break><restore-line-break><span class="hljs-keyword">import</span> requests<restore-line-break><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup<restore-line-break><span class="hljs-keyword">import</span> re<restore-line-break><span class="hljs-keyword">from</span> lxml <span class="hljs-keyword">import</span> html<restore-line-break><span class="hljs-keyword">from</span> urllib.parse <span class="hljs-keyword">import</span> urlsplit<restore-line-break><span class="hljs-keyword">import</span> csv<restore-line-break><restore-line-break><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">getAddress</span>:</span><restore-line-break>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, url=None, filename=<span class="hljs-string">"contacts.cvs"</span></span>):</span><restore-line-break>        <span class="hljs-keyword">if</span> url <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<restore-line-break>            self.filename = filename<restore-line-break>            self.url = url<restore-line-break>            self.mainurl = <span class="hljs-string">"{0.scheme}://{0.netloc}/"</span>.format(urlsplit(self.url))<restore-line-break>            self.addresses = []<restore-line-break>            content = self.geturlcontent(self.url)<restore-line-break>            <span class="hljs-keyword">if</span> content:<restore-line-break>                self.urls = self.geturlsfrommain(content)<restore-line-break><restore-line-break>            self.processurls(self.urls)<restore-line-break>            self.createexcel()<restore-line-break><restore-line-break>        <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><restore-line-break><restore-line-break>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">geturlcontent</span>(<span class="hljs-params">self, url</span>):</span><restore-line-break>        result = <span class="hljs-literal">None</span><restore-line-break>        <span class="hljs-keyword">if</span> url <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<restore-line-break>            result = requests.get(url)<restore-line-break><restore-line-break>        <span class="hljs-keyword">if</span> result.status_code == <span class="hljs-number">200</span>:<restore-line-break>            <span class="hljs-keyword">return</span> result.content<restore-line-break><restore-line-break>        <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><restore-line-break><restore-line-break>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">geturlsfrommain</span>(<span class="hljs-params">self, content</span>):</span><restore-line-break>        soup = BeautifulSoup(content, features=<span class="hljs-string">"lxml"</span>)<restore-line-break>        links = []<restore-line-break>        <span class="hljs-keyword">for</span> link <span class="hljs-keyword">in</span> soup.findAll(<span class="hljs-string">'a'</span>, attrs={<span class="hljs-string">'href'</span>: re.compile(<span class="hljs-string">"^companies"</span>)}):<restore-line-break>            links.append(link.get(<span class="hljs-string">'href'</span>))<restore-line-break><restore-line-break>        <span class="hljs-comment"># print(links)</span><restore-line-break><restore-line-break>        <span class="hljs-keyword">return</span> links<restore-line-break><restore-line-break>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">processurls</span>(<span class="hljs-params">self, urls</span>):</span><restore-line-break>        <span class="hljs-keyword">for</span> u <span class="hljs-keyword">in</span> urls:<restore-line-break>            url = <span class="hljs-string">"{}{}"</span>.format(self.mainurl,u)<restore-line-break>            print(url)<restore-line-break>            content = self.geturlcontent(url)<restore-line-break>            <span class="hljs-keyword">if</span> content:<restore-line-break>                data = self.getdatafromurls(content)<restore-line-break>                self.addresses.append(data)<restore-line-break><restore-line-break>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getdatafromurls</span>(<span class="hljs-params">self, content</span>):</span><restore-line-break>        root = html.fromstring(content)<restore-line-break>        data = {}<restore-line-break><restore-line-break>        xpathdata= <span class="hljs-string">"/html/body/div/table[2]/tr[1]/td[9]/table"</span><restore-line-break>        table = root.xpath(xpathdata)<restore-line-break>        i = <span class="hljs-number">0</span><restore-line-break>        <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> table[<span class="hljs-number">0</span>].xpath(<span class="hljs-string">".//tr"</span>):<restore-line-break>            values = row.xpath(<span class="hljs-string">".//td"</span>)<restore-line-break><restore-line-break>            <span class="hljs-keyword">if</span> values[<span class="hljs-number">2</span>].text_content() != <span class="hljs-string">''</span>:<restore-line-break>                key = values[<span class="hljs-number">0</span>].text_content()<restore-line-break>                key = self.removerubish(key)<restore-line-break><restore-line-break>                value = values[<span class="hljs-number">2</span>].text_content()<restore-line-break>                value = self.removerubishvalue(value)<restore-line-break><restore-line-break>            rawdata = {key: value}<restore-line-break>            data.update(rawdata)<restore-line-break><restore-line-break>            i += <span class="hljs-number">1</span><restore-line-break>            <span class="hljs-keyword">if</span> i == <span class="hljs-number">10</span>:<restore-line-break>                <span class="hljs-keyword">break</span><restore-line-break><restore-line-break>        <span class="hljs-keyword">return</span> data<restore-line-break><restore-line-break>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">removerubish</span>(<span class="hljs-params">self,key</span>):</span><restore-line-break>        key = re.sub(<span class="hljs-string">'\:|[ \t]+'</span>, <span class="hljs-string">''</span>, key)<restore-line-break>        key = key.lower()<restore-line-break>        <span class="hljs-keyword">return</span> key<restore-line-break><restore-line-break>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">removerubishvalue</span>(<span class="hljs-params">self,value</span>):</span><restore-line-break>        value = re.sub(<span class="hljs-string">'[ \t]+'</span>, <span class="hljs-string">' '</span>, value)<restore-line-break>        value = re.sub(<span class="hljs-string">'\n'</span>, <span class="hljs-string">''</span>, value)<restore-line-break>        value = re.sub(<span class="hljs-string">'\r'</span>, <span class="hljs-string">''</span>, value)<restore-line-break>        value = re.sub(<span class="hljs-string">r'[^\x00-\x7F]+'</span>,<span class="hljs-string">''</span>,value)<restore-line-break>        <span class="hljs-keyword">return</span> value<restore-line-break><restore-line-break>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">text</span>(<span class="hljs-params">self,elt</span>):</span><restore-line-break>        <span class="hljs-keyword">return</span> elt.text_content().replace(<span class="hljs-string">u'\xa0'</span>, <span class="hljs-string">u' '</span>)<restore-line-break><restore-line-break>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">createexcel</span>(<span class="hljs-params">self</span>):</span><restore-line-break>        keys = self.addresses[<span class="hljs-number">0</span>].keys()<restore-line-break>        <span class="hljs-keyword">with</span> open(self.filename, <span class="hljs-string">'w'</span>) <span class="hljs-keyword">as</span> output_file:<restore-line-break>            dict_writer = csv.DictWriter(output_file, keys, extrasaction=<span class="hljs-string">'ignore'</span>)<restore-line-break>            dict_writer.writeheader()<restore-line-break>            dict_writer.writerows(self.addresses)<restore-line-break><restore-line-break><restore-line-break><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:<restore-line-break>    g = getAddress(<span class="hljs-string">"http://www.petfoodnz.co.nz/directory.htm"</span>, <span class="hljs-string">"contacts.csv"</span>)<restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></code></pre></div><footer class="wrapper post__footer"><p class="post__last-updated">This article was updated on June 1, 2024</p><div class="post__share"></div><div class="post__bio bio"><img src="https://itheo.tech/media/website/64.png" loading="lazy" height="512" width="512" class="bio__avatar" alt="Theo van der Sluijs"><div><h3 class="bio__name"><a href="https://itheo.tech/authors/theo-van-der-sluijs/" rel="author">Theo van der Sluijs</a></h3></div></div></footer></article><nav class="post__nav"><div class="post__nav-inner"><div class="post__nav-prev"><svg width="1.041em" height="0.416em" aria-hidden="true"><use xlink:href="https://itheo.tech/assets/svg/svg-map.svg#arrow-prev"/></svg> <a href="https://itheo.tech/python-convert-medium-export-to-markdown-files.html" class="post__nav-link" rel="prev"><span>Previous</span> Python convert Medium export to Markdown files</a></div><div class="post__nav-next"><a href="https://itheo.tech/image-resize-python-automation-script.html" class="post__nav-link" rel="next"><span>Next</span> Image resize python automation script </a><svg width="1.041em" height="0.416em" aria-hidden="true"><use xlink:href="https://itheo.tech/assets/svg/svg-map.svg#arrow-next"/></svg></div></div></nav><div class="post__related related"><div class="wrapper"><h2 class="h5 related__title">You should also read:</h2><article class="related__item"><div class="feed__meta"><time datetime="2018-07-12T22:00" class="feed__date">July 12, 2018</time></div><h3 class="h1"><a href="https://itheo.tech/python-convert-medium-export-to-markdown-files.html">Python convert Medium export to Markdown files</a></h3></article><article class="related__item"><div class="feed__meta"><time datetime="2018-11-30T23:00" class="feed__date">November 30, 2018</time></div><h3 class="h1"><a href="https://itheo.tech/image-resize-python-automation-script.html">Image resize python automation script</a></h3></article><article class="related__item"><div class="feed__meta"><time datetime="2018-12-19T23:00" class="feed__date">December 19, 2018</time></div><h3 class="h1"><a href="https://itheo.tech/get-colors-from-images-python-script.html">Get colors from images python script</a></h3></article></div></div></main><footer class="footer"><div class="footer__copyright"><p>iTheo.Tech</p></div><button onclick="backToTopFunction()" id="backToTop" class="footer__bttop" aria-label="Back to top" title="Back to top"><svg><use xlink:href="https://itheo.tech/assets/svg/svg-map.svg#toparrow"/></svg></button></footer></div><script defer="defer" src="https://itheo.tech/assets/js/scripts.min.js?v=f47c11534595205f20935f0db2a62a85"></script><script>window.publiiThemeMenuConfig={mobileMenuMode:'sidebar',animationSpeed:300,submenuWidth: 'auto',doubleClickTime:500,mobileMenuExpandableSubmenus:true,relatedContainerForOverlayMenuSelector:'.top'};</script><script>var images = document.querySelectorAll('img[loading]');
        for (var i = 0; i < images.length; i++) {
            if (images[i].complete) {
                images[i].classList.add('is-loaded');
            } else {
                images[i].addEventListener('load', function () {
                    this.classList.add('is-loaded');
                }, false);
            }
        }</script></body></html>