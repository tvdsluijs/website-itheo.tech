<!DOCTYPE html><html lang="en-gb"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Get 404 and source pages with a python script - iTheo.Tech</title><meta name="description" content="So the other day I had to get all 404 pages from a website with the source pages and I wanted to have them in a csv file. So I opened up Visual Studio Code and be thinking about what code I should put down...."><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://itheo.tech/get-404-and-source-pages-with-a-python-script.html"><link rel="alternate" type="application/atom+xml" href="https://itheo.tech/feed.xml"><link rel="alternate" type="application/json" href="https://itheo.tech/feed.json"><meta property="og:title" content="Get 404 and source pages with a python script"><meta property="og:image" content="https://itheo.tech/media/posts/73/c847c1e0c432af1e14fd958d3de9194f.jpeg"><meta property="og:image:width" content="1600"><meta property="og:image:height" content="1067"><meta property="og:site_name" content="iTheo.Tech"><meta property="og:description" content="So the other day I had to get all 404 pages from a website with the source pages and I wanted to have them in a csv file. So I opened up Visual Studio Code and be thinking about what code I should put down...."><meta property="og:url" content="https://itheo.tech/get-404-and-source-pages-with-a-python-script.html"><meta property="og:type" content="article"><link rel="stylesheet" href="https://itheo.tech/assets/css/style.css?v=6fbb1e8931a5afe843374fd67c192c86"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://itheo.tech/get-404-and-source-pages-with-a-python-script.html"},"headline":"Get 404 and source pages with a python script","datePublished":"2023-03-31T17:47","dateModified":"2024-06-01T19:42","image":{"@type":"ImageObject","url":"https://itheo.tech/media/posts/73/c847c1e0c432af1e14fd958d3de9194f.jpeg","height":1067,"width":1600},"description":"So the other day I had to get all 404 pages from a website with the source pages and I wanted to have them in a csv file. So I opened up Visual Studio Code and be thinking about what code I should put down....","author":{"@type":"Person","name":"Theo van der Sluijs","url":"https://itheo.tech/authors/theo-van-der-sluijs/"},"publisher":{"@type":"Organization","name":"Theo van der Sluijs","logo":{"@type":"ImageObject","url":"https://itheo.tech/media/website/itheo.tech-500x125-logo.png","height":125,"width":500}}}</script><noscript><style>img[loading] {
                    opacity: 1;
                }</style></noscript></head><body><div class="site-container"><header class="top" id="js-header"><a class="logo" href="https://itheo.tech/"><img src="https://itheo.tech/media/website/itheo.tech-500x125-logo.png" alt="iTheo.Tech" width="500" height="125"></a><div class="search"><div class="search__overlay js-search-overlay"><div class="search__overlay-inner"><button class="search__close js-search-close" aria-label="Close">Close</button></div></div><button class="search__btn js-search-btn" aria-label="Search"><svg role="presentation" focusable="false"><use xlink:href="https://itheo.tech/assets/svg/svg-map.svg#search"/></svg></button></div></header><main><article class="post"><div class="hero"><figure class="hero__image hero__image--overlay"><img src="https://itheo.tech/media/posts/73/c847c1e0c432af1e14fd958d3de9194f.jpeg" srcset="https://itheo.tech/media/posts/73/responsive/c847c1e0c432af1e14fd958d3de9194f-xs.webp 300w, https://itheo.tech/media/posts/73/responsive/c847c1e0c432af1e14fd958d3de9194f-sm.webp 480w, https://itheo.tech/media/posts/73/responsive/c847c1e0c432af1e14fd958d3de9194f-md.webp 768w, https://itheo.tech/media/posts/73/responsive/c847c1e0c432af1e14fd958d3de9194f-lg.webp 1024w, https://itheo.tech/media/posts/73/responsive/c847c1e0c432af1e14fd958d3de9194f-xl.webp 1360w, https://itheo.tech/media/posts/73/responsive/c847c1e0c432af1e14fd958d3de9194f-2xl.webp 1600w" sizes="(max-width: 1600px) 100vw, 1600px" loading="eager" height="1067" width="1600" alt=""></figure><header class="hero__content"><div class="wrapper"><div class="post__meta"><time datetime="2023-03-31T17:47">March 31, 2023</time></div><h1>Get 404 and source pages with a python script</h1><div class="post__meta post__meta--author"><img src="https://itheo.tech/media/website/64.png" loading="eager" height="512" width="512" class="post__author-thumb" alt="Theo van der Sluijs"> <a href="https://itheo.tech/authors/theo-van-der-sluijs/" class="feed__author">Theo van der Sluijs</a></div></div></header></div><div class="wrapper post__entry"><p>So the other day I had to get all 404 pages from a website with the source pages and I wanted to have them in a csv file.</p><p>So I opened up Visual Studio Code and be thinking about what code I should put down.... and there was copilot! A great helper!!</p><p>So the assignment is:</p><blockquote><p>Let's create a python script that recursively checks a site for 404 pages, the output should be put in a csv file with in the first column the 404 url ​​and in the second column should contain the url where to find the 404 url ​​as a link is. There is no need to scan urls that fall outside the domain.</p></blockquote><p>And off we go!</p><p>To create a Python script that recursively checks a site for 404 pages, you can use the <code>requests</code>, <code>BeautifulSoup</code>, and <code>csv</code> libraries. Make sure you have the <code>requests</code> and <code>BeautifulSoup</code> libraries installed by running the following commands:</p><pre><code class="lang-bash">pip install requests<restore-line-break>pip install beautifulsoup4<restore-line-break></restore-line-break></restore-line-break></code></pre><p>Here's a script that accomplishes the task:</p><pre><code class="lang-python"><span class="hljs-keyword">import</span> requests<restore-line-break><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup<restore-line-break><span class="hljs-keyword">import</span> csv<restore-line-break><span class="hljs-keyword">from</span> urllib.parse <span class="hljs-keyword">import</span> urlparse, urljoin<restore-line-break><restore-line-break><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">is_valid</span>(<span class="hljs-params">url</span>):</span><restore-line-break>    parsed = urlparse(url)<restore-line-break>    <span class="hljs-keyword">return</span> bool(parsed.netloc) <span class="hljs-keyword">and</span> bool(parsed.scheme)<restore-line-break><restore-line-break><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_all_links</span>(<span class="hljs-params">url</span>):</span><restore-line-break>    <span class="hljs-keyword">try</span>:<restore-line-break>        response = requests.get(url)<restore-line-break>        soup = BeautifulSoup(response.text, <span class="hljs-string">"html.parser"</span>)<restore-line-break>        <span class="hljs-keyword">return</span> [urljoin(url, link.get(<span class="hljs-string">"href"</span>)) <span class="hljs-keyword">for</span> link <span class="hljs-keyword">in</span> soup.find_all(<span class="hljs-string">"a"</span>)]<restore-line-break>    <span class="hljs-keyword">except</span>:<restore-line-break>        <span class="hljs-keyword">return</span> []<restore-line-break><restore-line-break><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">crawl</span>(<span class="hljs-params">url, domain, visited, csv_writer</span>):</span><restore-line-break>    <span class="hljs-keyword">if</span> url <span class="hljs-keyword">in</span> visited:<restore-line-break>        <span class="hljs-keyword">return</span><restore-line-break><restore-line-break>    visited.add(url)<restore-line-break>    print(<span class="hljs-string">f"Visiting: <span class="hljs-subst">{url}</span>"</span>)<restore-line-break><restore-line-break>    links = get_all_links(url)<restore-line-break>    <span class="hljs-keyword">for</span> link <span class="hljs-keyword">in</span> links:<restore-line-break>        <span class="hljs-keyword">if</span> urlparse(link).netloc == domain:<restore-line-break>            response = requests.head(link, allow_redirects=<span class="hljs-literal">True</span>)<restore-line-break>            <span class="hljs-keyword">if</span> response.status_code == <span class="hljs-number">404</span>:<restore-line-break>                csv_writer.writerow([link, url])<restore-line-break>            <span class="hljs-keyword">else</span>:<restore-line-break>                crawl(link, domain, visited, csv_writer)<restore-line-break><restore-line-break><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">main</span>(<span class="hljs-params">start_url, output_file</span>):</span><restore-line-break>    domain = urlparse(start_url).netloc<restore-line-break>    visited = set()<restore-line-break><restore-line-break>    <span class="hljs-keyword">with</span> open(output_file, <span class="hljs-string">"w"</span>, newline=<span class="hljs-string">""</span>, encoding=<span class="hljs-string">"utf-8"</span>) <span class="hljs-keyword">as</span> csvfile:<restore-line-break>        csv_writer = csv.writer(csvfile)<restore-line-break>        csv_writer.writerow([<span class="hljs-string">"404 URL"</span>, <span class="hljs-string">"Source URL"</span>])<restore-line-break>        crawl(start_url, domain, visited, csv_writer)<restore-line-break><restore-line-break><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:<restore-line-break>    start_url = <span class="hljs-string">"https://example.com"</span>  <span class="hljs-comment"># Replace with the website you want to crawl</span><restore-line-break>    output_file = <span class="hljs-string">"404_errors.csv"</span><restore-line-break><restore-line-break>    <span class="hljs-keyword">if</span> is_valid(start_url):<restore-line-break>        main(start_url, output_file)<restore-line-break>    <span class="hljs-keyword">else</span>:<restore-line-break>        print(<span class="hljs-string">"Invalid starting URL. Please provide a valid URL."</span>)<restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></restore-line-break></code></pre><p>Replace <a target="_blank" href="https://example.com" rel="noopener"><code>https://example.com</code></a> with the website you want to crawl. This script will crawl the website and store any 404 URLs along with their source URL in a CSV file named <code>404_errors.csv</code>.</p><p>Please note that this script is relatively simple and might not cover all edge cases or handle very large websites efficiently. Be aware that web scraping may also violate some websites' terms of service, and you should always respect website owners' wishes and robots.txt files.</p><p>And it just worked!</p></div><footer class="wrapper post__footer"><p class="post__last-updated">This article was updated on June 1, 2024</p><div class="post__share"></div><div class="post__bio bio"><img src="https://itheo.tech/media/website/64.png" loading="lazy" height="512" width="512" class="bio__avatar" alt="Theo van der Sluijs"><div><h3 class="bio__name"><a href="https://itheo.tech/authors/theo-van-der-sluijs/" rel="author">Theo van der Sluijs</a></h3></div></div></footer></article><nav class="post__nav"><div class="post__nav-inner"><div class="post__nav-prev"><svg width="1.041em" height="0.416em" aria-hidden="true"><use xlink:href="https://itheo.tech/assets/svg/svg-map.svg#arrow-prev"/></svg> <a href="https://itheo.tech/updating-the-creality-neo-max-screen.html" class="post__nav-link" rel="prev"><span>Previous</span> Updating the Creality Neo (max) screen</a></div><div class="post__nav-next"><a href="https://itheo.tech/checking-unique-404-pages-with-python.html" class="post__nav-link" rel="next"><span>Next</span> Checking unique 404 pages with Python </a><svg width="1.041em" height="0.416em" aria-hidden="true"><use xlink:href="https://itheo.tech/assets/svg/svg-map.svg#arrow-next"/></svg></div></div></nav><div class="post__related related"><div class="wrapper"><h2 class="h5 related__title">You should also read:</h2><article class="related__item"><div class="feed__meta"><time datetime="2018-11-30T23:00" class="feed__date">November 30, 2018</time></div><h3 class="h1"><a href="https://itheo.tech/image-resize-python-automation-script.html">Image resize python automation script</a></h3></article><article class="related__item"><div class="feed__meta"><time datetime="2018-12-11T23:00" class="feed__date">December 11, 2018</time></div><h3 class="h1"><a href="https://itheo.tech/fake-jekyll-posts-generator-script.html">Fake Jekyll posts generator script</a></h3></article><article class="related__item"><div class="feed__meta"><time datetime="2018-12-19T23:00" class="feed__date">December 19, 2018</time></div><h3 class="h1"><a href="https://itheo.tech/get-colors-from-images-python-script.html">Get colors from images python script</a></h3></article></div></div></main><footer class="footer"><div class="footer__copyright"><p>iTheo.Tech</p></div><button onclick="backToTopFunction()" id="backToTop" class="footer__bttop" aria-label="Back to top" title="Back to top"><svg><use xlink:href="https://itheo.tech/assets/svg/svg-map.svg#toparrow"/></svg></button></footer></div><script defer="defer" src="https://itheo.tech/assets/js/scripts.min.js?v=f47c11534595205f20935f0db2a62a85"></script><script>window.publiiThemeMenuConfig={mobileMenuMode:'sidebar',animationSpeed:300,submenuWidth: 'auto',doubleClickTime:500,mobileMenuExpandableSubmenus:true,relatedContainerForOverlayMenuSelector:'.top'};</script><script>var images = document.querySelectorAll('img[loading]');
        for (var i = 0; i < images.length; i++) {
            if (images[i].complete) {
                images[i].classList.add('is-loaded');
            } else {
                images[i].addEventListener('load', function () {
                    this.classList.add('is-loaded');
                }, false);
            }
        }</script></body></html>